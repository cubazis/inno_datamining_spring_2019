{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Mining. Lab #2\n",
    "================\n",
    "\n",
    "[SymPy](https://docs.sympy.org/latest/tutorial/preliminaries.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "from itertools import combinations\n",
    "init_printing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate k-subsets from set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsets(S, k):\n",
    "    return [set(s)for s in combinations(S, k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAAWCAYAAADEvflXAAAABHNCSVQICAgIfAhkiAAABOdJREFUeJztnF2oFVUUx396jSwqb3bxRhKaYPShJCFBVHT6AkEuJfYUUb5EQSE9XKgX6RZIt0KIipAeSuj6Uj0UfWAQNVaUEGJmYR8Ex0hRykoib3Ure1hruONpn733mbP3zDRnfjDMueesvfaa/1ln35m19ww0NDQ0dNACTmS2Lx32twG7gGPA38CqmMEFYgKYAQ4DrwIXlhqNP43WxVF3rUc4+Xd+Iv1gnsF4J5AAP1ocXgJMAb8BLwMHNZBObgWuRQS9DDgT2A7cbvHtwznAOmAtsBJYDPwJ7ANe0O0fQ7sEmK/x3AycB1zRZyyxKVtrgMeA1UiSjQDTwAEk8Z4BjhraJNRT67y550tsrY8DD+vrDcASk1ELGSUmPAK+V203Ouw+Vbtfgf36esrDv4t71NchJOEfBZ4HftH3XwHmOHzsRr60MwLEE5OytQZJ9l2IxpPA08An2sdB4HxH+zppHSL3bBSpdULmzCBLC//BYJPa3uSwuw5YjoiT+g+RoNcDY8DcjvfPBb7TftY7fGxXO5e4ZVO21iD/dUxs1n6edbSvk9Yhcs9GkVonZAaDzgPyZUj3Mw6794Bv6DL69MG7wOv893TsMLBVX7ccPtLYh6xW5VO21gC/d3n/Jd0vd7Svk9Yhcs9GaVrnHQyqTCrGX6VGMRiM6f6zUqOoDjFzL7rWpgKiD8O6nw4VSCDmAXfo6x0O23QEXhAvnCBUSetx5Fp0AVLkuhpJzklHu0HQupfc86FwrfMMBnOAa5DT0QM52sdkElgBvAW87bBt674F7I0XUl9UTetxYDTz9w6kIv2Do11b9y3qq3UvuedDqVq3sBcQ1wBbmK1sbu1i5/IfqqjVyUb1vx9Y6GG/GBFuBrke2wwsjRRbr1Rd61Fkeu0rpKp+ucO+zlpD77nXCzG1Tsg5m/Aks4sU9gGXOoLq5j9GgqZTQl8gVV1f7kbmXdPjagWPLB9V1jrLEuAP4HMP27pqnTf3eiWG1gl9TC2ehSxqmAa+p7eKZeo/dILez+wXuaiHdmu13YdIApwSOK5+qaLWJvZoXyMWm7pqnTf38hJa64QA6wym1HaFh22n/5AJ+oD63INdIBNbtO2NAeOJQVW07sYR7etsi00dte4n9/ISWuuEAOsM0gJL6OsjgG1IgBscdpuQos1u4Absy6dNpIK2A8QSk7K1vgjz6e9c5Hp0EfAR8LPFR920zpN726iO1kbyTi2m86muweQW3WD2IK9EhAERcbyjTerTNld7J/AIciPJB5iXj7Yz/Zjw6cfHJjZla70GeAJ4H/gWWRs/itwHsQxZbHOXI7Y6aZ0396qktZG8g4HvKrdViHhZlukGMhJ3JuhKZH39mxa/F+h+CLluM7ET+2CQYjsWn1hiU7bW7wDPAVchN0ANIzfyfA28CDwF/OQZYx20zpt7VdLaSQv/msGDaruunw4NDCMj7uOB/Zp4DTmG0S6fFxmLjUbr4hgErbMkOAqI6WZ7nsF6tXkDuSEi1LLmMWQFVcwpmlOR2zuP6dYt9iJi8aHRujgGQeuuzzPIshQ5K0i3+ywdn4ZMp2Qd/l8eApGN+aFSo/Gj0bo4BkHr0zn5dz6RfpCtGbTxu0QAmY9djdzOeTGyhtr0wI2qkSCFlaPAx8gzAKpOo3VxDILWx/H/nTc0NDQ0NDQMLP8C/N8haQKugfUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "[set([1, 2]), set([1, 3]), set([2, 3])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsets({1, 2, 3}, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And sometimes I want to print a list, each on its own line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all(iterable):\n",
    "    for item in iterable:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2}\n",
      "{1, 3}\n",
      "{2, 3}\n"
     ]
    }
   ],
   "source": [
    "print_all(subsets({1, 2, 3}, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In association rule mining, we try to discover rules based on item sets.\n",
    "\n",
    "Our input data is a list of _transactions_. Each transaction contains a set of items (called an _itemset_).\n",
    "For example, this table represents the set of items bought by a customer in a single transaction:\n",
    "\n",
    "| TID | Items |\n",
    "| --- | ----- |\n",
    "| 1 | Bread, Milk |\n",
    "| 2 | Bread, Diaper, Beer, Eggs |\n",
    "| 3 | Milk, Diaper, Beer, Coke |\n",
    "| 4 | Bread, Milk, Diaper, Beer |\n",
    "| 4 | Bread, Milk, Diaper, Coke |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = [\n",
    " {'Bread', 'Milk'},\n",
    " {'Beer', 'Bread', 'Diaper', 'Eggs'},\n",
    " {'Beer', 'Coke', 'Diaper', 'Milk'},\n",
    " {'Beer', 'Bread', 'Diaper', 'Milk'},\n",
    " {'Bread', 'Coke', 'Diaper', 'Milk'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "association rules, such as:\n",
    "\n",
    "$$ \\{\\text{Milk}, \\text{Bread}\\} \\Rightarrow \\{\\text{Eggs}, \\text{Coke}\\} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itemsets\n",
    "========\n",
    "\n",
    "An _itemset_ is simply a set of items, such as $\\{ \\text{Milk}, \\text{Bread}, \\text{Eggs} \\}$.\n",
    "\n",
    "The frequency of occurrence of an _itemset_ is called support count.\n",
    "\n",
    "$$ \\sigma(X) = \\|\\{ x \\in T \\:|\\: X \\subseteq x \\}\\| $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_count(X, T):\n",
    "    return S(sum(1 for x in T if X <= x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA0AAAASCAYAAACAa1QyAAAABHNCSVQICAgIfAhkiAAAAMJJREFUKJHF0j9LQlEYB+DH6BNYhJ/HxcmpD9CgQxCImxAIbi5u7eLSJji5NzQGDRItDtHQ3J0aSnS4LxJytBMN/eBw4XCe+77nD3/MCdqYYYkPFLhHC0cpdIk13nCLIcZ4j/kpKruojmbijzW8Bjz/TevXgW7s6zORz/h+5VY5xiIqNXLRKMA8F3QCPKOaA64CPClP8Md0AyxwlgN6AR5xmgP6AR4c2MP3Z3GBCVbKSywS619izTaDqHJo3OW0+8/ZALBUMPfsVQVVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_count({'Milk', 'Bread', 'Diaper'}, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support is the _proportion_ of transactions that contain an itemset.\n",
    "\n",
    "$$ s(X) = \\frac{\\sigma(X)}{\\|\\text{T}\\|} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support(X, T):\n",
    "    return support_count(X, T) / len(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACEAAAAUCAYAAAADU1RxAAAABHNCSVQICAgIfAhkiAAAAclJREFUSInt1U+ITXEUB/AP8+JlYQp5ViR2lJWlxGaSELKRWJCNkmxoSqysLOQtWKixs1BmxSwsSJaKTIwiXiwolMn/v8/idybX9bsz700jFr71697fOd9z7vd37znn8o9hLvZgEA/xAaO4gd2YPk5sA99wqmBroV2xnheDa4X7bTiNZ7iKJ5F8C85iXXDaGRGbQuRgyT6Kkxn+26rTrMUGv594QQhqY2tF7BBeoqdga8WaMvSHiGbG14tPGCjZOxZRm5gCvsT1a8a3HjNwMeObiR1YiHe4g+tS/XSFGoalN9GX8V+QvnG9ZG/JF+UjrO5WxIkIvpTx1fEmhJRxVKqzBmZhOc7gO95jRacC9oeAEczJ+DeGf3unCf08VLmTstgX5LtSh+QwIBVlbxcilkbeVxMRDwRxGPMrOD1SWw51IQBmR+6P45EOBekW5o3DWxO8vV2K6Iu4e1WEI0G4KV8DRTSlVmtkfMsq4hfhQTyjf8w4rUDYhXORuCmN3DJawYGnsV+V4R3DYWn8P5Y6aIk0U+q4jM34nAus+uGMrWvBXRn7gxkBpDlwHvfxWhp2L3AFO/16+EnjeIhYPBXJJosR3P6bAv7jj+EHn6J9G5S625EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "2/5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support({'Milk', 'Bread', 'Diaper'}, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the _support_ is higher than a given ratio, it is called a _frequent itemset_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules\n",
    "=====\n",
    "\n",
    "A rule is in form of $X \\Rightarrow Y$ where $X$ and $Y$ are itemsets. For example:\n",
    "\n",
    "$$ \\{ \\text{Milk}, \\text{Diaper} \\} \\Rightarrow \\{ \\text{Beer} \\} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = ({'Milk', 'Diaper'}, {'Beer'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _support_ of the rule is the fraction of transactions that contain both $X$ and $Y$.\n",
    "\n",
    "$$ s(X \\Rightarrow Y) = s(X \\cup Y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func (xy):\n",
    "    x, y = xy\n",
    "    return x, y\n",
    "\n",
    "def rule_support(xy, T):\n",
    "    x, y = func(xy)\n",
    "    return support(x | y, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACEAAAAUCAYAAAADU1RxAAAABHNCSVQICAgIfAhkiAAAAclJREFUSInt1U+ITXEUB/AP8+JlYQp5ViR2lJWlxGaSELKRWJCNkmxoSqysLOQtWKixs1BmxSwsSJaKTIwiXiwolMn/v8/idybX9bsz700jFr71697fOd9z7vd37znn8o9hLvZgEA/xAaO4gd2YPk5sA99wqmBroV2xnheDa4X7bTiNZ7iKJ5F8C85iXXDaGRGbQuRgyT6Kkxn+26rTrMUGv594QQhqY2tF7BBeoqdga8WaMvSHiGbG14tPGCjZOxZRm5gCvsT1a8a3HjNwMeObiR1YiHe4g+tS/XSFGoalN9GX8V+QvnG9ZG/JF+UjrO5WxIkIvpTx1fEmhJRxVKqzBmZhOc7gO95jRacC9oeAEczJ+DeGf3unCf08VLmTstgX5LtSh+QwIBVlbxcilkbeVxMRDwRxGPMrOD1SWw51IQBmR+6P45EOBekW5o3DWxO8vV2K6Iu4e1WEI0G4KV8DRTSlVmtkfMsq4hfhQTyjf8w4rUDYhXORuCmN3DJawYGnsV+V4R3DYWn8P5Y6aIk0U+q4jM34nAus+uGMrWvBXRn7gxkBpDlwHvfxWhp2L3AFO/16+EnjeIhYPBXJJosR3P6bAv7jj+EHn6J9G5S625EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "2/5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_support(rule, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _confidence_ of the rule tells you how many transactions that contains $X$ also contains $Y$ (in form of proportion).\n",
    "\n",
    "$$ c(X \\Rightarrow Y) = \\frac{\\sigma(X \\cup Y)}{\\sigma(X)} \\left(= \\frac{s(X \\Rightarrow Y)}{s(X)}\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-64-c3075cfbe438>, line 3)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-c3075cfbe438>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    return ???\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def rule_confidence(xy, T):\n",
    "    x, y = func(xy)\n",
    "    return ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_confidence(rule, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association Rule Mining\n",
    "=======================\n",
    "\n",
    "In association rule mining, we want to find all rules that has enough _support_ and _confidence_. In other words, we want to find $\\{ X \\Rightarrow Y \\:|\\: s(X \\Rightarrow Y) > s_{min}, c(X \\Rightarrow Y) > c_{min} \\}$.\n",
    "\n",
    "We are using 2-step approach:\n",
    "\n",
    "- First, finding frequent itemsets with enough support.\n",
    "    - For example, $\\{A, B, C\\}$\n",
    "- Then, generate rules from these itemsets.\n",
    "    - We can generate rules by finding binary partitions of a given itemset.\n",
    "    - For example, from $\\{A, B, C\\}$, we can generate 6 rules:\n",
    "    - Note that support of these rules are all the same.\n",
    "    - We then select only the rules with enough confidence.\n",
    "        - $\\{A\\} \\Rightarrow \\{C,B\\}$\n",
    "        - $\\{C\\} \\Rightarrow \\{A,B\\}$\n",
    "        - $\\{B\\} \\Rightarrow \\{A,C\\}$\n",
    "        - $\\{A,C\\} \\Rightarrow \\{B\\}$\n",
    "        - $\\{A,B\\} \\Rightarrow \\{C\\}$\n",
    "        - $\\{C,B\\} \\Rightarrow \\{A\\}$\n",
    "\n",
    "frequent itemsets supposed to be given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = [\n",
    " {'A', 'B', 'E'},\n",
    " {'B', 'D'},\n",
    " {'B', 'C'},\n",
    " {'A', 'B', 'D'},\n",
    " {'A', 'C'},\n",
    " {'B', 'C'},\n",
    " {'A', 'C'},\n",
    " {'A', 'B', 'C', 'E'},\n",
    " {'A', 'B', 'C'},\n",
    "]\n",
    "\n",
    "cmin = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a Frequent Itemset\n",
    "------------------------\n",
    "\n",
    "We can use a naive algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent itemset `l`\n",
    "def find_rules(l, T):\n",
    "    rules = []\n",
    "    for n in range(1, len(l)):\n",
    "        for c in subsets(l, n):\n",
    "            rule = (set(c), l - set(c))\n",
    "            if rule_confidence(rule, T) >= cmin:\n",
    "                rules.append(rule)\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It just tries all \"binary partitions\" of the frequent itemset `l`, and only emits rules with enough confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(rule, rule_confidence(rule, T)) for rule in find_rules({'A', 'B', 'E'}, T)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without a Frequent Itemset\n",
    "--------------------------\n",
    "\n",
    "Now, recall about having to find the frequent itemsets. What should we do?\n",
    "\n",
    "For a large dataset, this is impractical. To find all the candidates, we must try all subsets of all items!\n",
    "If we have $d$ items, the number of subsets become $2^d$.\n",
    "See how fast it grows!\n",
    "What can we do to help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori Principle\n",
    "-----------------\n",
    "\n",
    "You know, given that $A \\subseteq B$, then $C \\subseteq B$ as well if $C \\subseteq B$.\n",
    "It is also obvious that if $A \\subseteq B$, $s(A) \\geq s(B)$, since every item in $A$ also appear in $B$.\n",
    "\n",
    "Apriori priciple says:\n",
    "_\"If an itemset is frequent, then all of its subsets must also be frequent.\"_\n",
    "\n",
    "From that, we know that if an itemset is _infrequent_, all its supersets are also infrequent.\n",
    "\n",
    "Assume the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = [\n",
    "  {'A', 'C', 'D'},\n",
    "  {'B', 'C', 'E'},\n",
    "  {'A', 'B', 'C', 'E'},\n",
    "  {'B', 'E'},\n",
    "  {'A', 'B', 'C', 'E'}\n",
    "]\n",
    "\n",
    "smin = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Starting Small\n",
    "\n",
    "So here's our approach.\n",
    "\n",
    "- First, we find all frequent itemsets of size 1 (called _frequent 1-itemsets_).\n",
    "- Next, we \"prune\" itemsets whose support is too low.\n",
    "- Then, we generate frequent _2_-itemsets from the remaining 1-itemsets.\n",
    "- Again, we \"prune\" itemsets whose support is too low.\n",
    "- Increase the size and repeat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Frequent 1-itemsets\n",
    "\n",
    "First, let's generate frequent 1-itemsets.\n",
    "Before that, I will create a function to union multiple sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_all(sets):\n",
    "    result = set()\n",
    "    for c in sets:\n",
    "        result = result | c\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_all([{1, 2}, {2, 3}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_all([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, some code to find frequent 1-itemsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequent_1(T):\n",
    "  items = union_all(T)\n",
    "  return [{item}\n",
    "    for item in items\n",
    "      if support({item}, T) >= smin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = frequent_1(T)\n",
    "L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, \"D\" is eliminated from the candidates.\n",
    "That means any itemset with \"D\" in it will not be frequent enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding It\n",
    "\n",
    "Next, we generate frequent 2-itemsets from 1-itemsets.\n",
    "The easiest way to do it is to put these items together and select 2 items. First, we put them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_all(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C2 = subsets(_, 2)\n",
    "print_all(C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the candidate itemsets. But maybe... not all of them are frequent enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each candidate $c$ in `C2`,\n",
    "we must make sure at all of $c$'s 1-subset is in `L1`.\n",
    "Why? If one of $c$'s subset (let's call it $s$) is not in `L1`,\n",
    "it means that that $s$ has already been pruned, because $s$ is not frequent enough.\n",
    "Since $c$ is a superset of $s$, $c$ will also not be frequent enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_candidate(c, P):\n",
    "    for s in subsets(c, len(c) - 1):\n",
    "        if s not in P: return false\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F2 = [c for c in C2 if good_candidate(c, L1)]\n",
    "print_all(F2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it seems that every candidate is a good one. Anyway, now we have the finalists!\n",
    "For the final round, you might have guessed it:\n",
    "We simply check the support to see if each item set is frequent enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2 = [f for f in F2 if support(f, T) >= smin]\n",
    "print_all(L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, all of them are frequent enough! So, now we have the 2-itemsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving On"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate `L3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates(P, k):\n",
    "    return subsets(union_all(P), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C3 = generate_candidates(L2, 3)\n",
    "print_all(C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F3 = [c for c in C3\n",
    "         if good_candidate(c, L2)]\n",
    "print_all(F3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L3 = [f for f in F3\n",
    "         if support(f, T) >= smin]\n",
    "print_all(L3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalizing It\n",
    "\n",
    "We can turn the above steps into this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequent_k(P, k, T):\n",
    "    # YOUR CODE HERE\n",
    "    candidates = generate_candidates(P, k)\n",
    "    good_candidates = []\n",
    "    for c in candidates:\n",
    "        if good_candidate(c, P):\n",
    "            good_candidates.append(c)\n",
    "    result = []\n",
    "    for c in candidates:\n",
    "        if support(f, T) >= smin:\n",
    "            out.append(c)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use that function to generate `L4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L4 = frequent_k(L3, 4, T)\n",
    "L4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, generating `L5` will return no itemsets, which concludes the Apriori algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L5 = frequent_k(L4, 5, T)\n",
    "L5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting It Together\n",
    "-------------------\n",
    "\n",
    "We take all the previous answers to find the frequent itemsets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 + L2 + L3 + L4 + L5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing It Up\n",
    "-------------\n",
    "\n",
    "Finally, here's the apriori algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(T):\n",
    "    result = []\n",
    "    # YOUR CODE HERE \n",
    "    l = frequent_1(T)\n",
    "    for i in range(2, len(l)  + 1):\n",
    "        result.append(l)\n",
    "        l = frequent_k(l, i, T)\n",
    "        if not l:\n",
    "            break;\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = apriori(T)\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each frequent itemsets, we generate rules from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmin = 0.75\n",
    "\n",
    "[rule\n",
    "  for itemset in L\n",
    "    for rule in find_rules(itemset, T)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lift\n",
    "--------\n",
    "\n",
    "How can you be sure that there really is a correlation between the itemset $X$ and $Y$?\n",
    "\n",
    "Take an example from the slides:\n",
    "\n",
    "- 90% of customers buy coffee.\n",
    "- 25% of customers buy tea.\n",
    "- 20% of customers buy both.\n",
    "\n",
    "After filling Venn diagram, here's our transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = (\n",
    "  20 * [{'coffee', 'tea'}] +\n",
    "  70 * [{'coffee'}] +\n",
    "   5 * [{'tea'}] +\n",
    "   5 * [set()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $\\{\\text{coffee}, \\text{tea}\\}$ is a frequent itemset,\n",
    "let's mine some rules!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = find_rules({'coffee', 'tea'}, T)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we mined the rule $\\{\\text{tea}\\} \\Rightarrow \\{\\text{coffee}\\}$.\n",
    "How confident we are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = ({'tea'}, {'coffee'})\n",
    "rule_confidence(rule, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that __80% of customers that buy tea also buys coffee__.\n",
    "We're highly confident, at 80 percent!\n",
    "But is 80% good?\n",
    "\n",
    "Does it really mean that the customer buys coffee _because_ they buys tea?\n",
    "To find out, let's remove the condition.\n",
    "Let's see how many people buys coffee \"no matter what:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = (set(), {'coffee'})\n",
    "rule_confidence(rule, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called the unconditional, _expected confidence_.\n",
    "As you see, people who buy tea are actually less likely to buy coffee.\n",
    "This is a _negative correlation_.\n",
    "\n",
    "To quantify this correlation, we use a measure called \"lift:\"\n",
    "\n",
    "$$ L(X \\Rightarrow Y) = \\frac{c(X \\Rightarrow Y)}{c(\\varnothing \\Rightarrow Y)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_lift(xy, T):\n",
    "    ### YOUR CODE HERE\n",
    "    tmp = rule_confidence(xy, T)\n",
    "    tmp1 = rule_confidence((set(), xy[1]), T)\n",
    "    return tmp/tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = ({'tea'}, {'coffee'})\n",
    "rule_lift(rule, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"lift\" measure tells us the correlation of the rule.\n",
    "\n",
    "- $L > 1 \\Rightarrow$ positive correlation\n",
    "- $L = 1 \\Rightarrow$ independence\n",
    "- $L < 1 \\Rightarrow$ negative correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this concludes this notebook regarding association rules and apriori algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The Intuition Behind the Apriori Algorithm](https://medium.com/weekly-data-science/the-intuition-behind-the-apriori-algorithm-4efe312ccc3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hash Functions for Data Mining](https://medium.com/weekly-data-science/hash-functions-for-data-mining-55e9c7760703)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Suppose we have transactions that satisfy the following assumptions: \n",
    "- s, the support threshold, is 10,000.\n",
    "- There are one million items, which are represented by the integers 0,1,...,999999.\n",
    "- There are N frequent items, that is, items that occur 10,000 times or more.\n",
    "- There are one million pairs that occur 10,000 times or more.\n",
    "- There are 2M pairs that occur exactly once. M of these pairs consist of two frequent items, the other M each have at least one nonfrequent item.\n",
    "- No other pairs occur at all.\n",
    "- Integers are always represented by 4 bytes.\n",
    "\n",
    "Suppose we run the a-priori algorithm to find frequent pairs and can choose on the second pass between the triangular-matrix method for counting candidate pairs (a triangular array $count[i][j]$ that holds an integer count for each pair of items (i, j) where i < j) and a hash table of item-item-count triples. Neglect in the first case the space needed to translate between original item numbers and numbers for the frequent items, and in the second case neglect the space needed for the hash table. Assume that item numbers and counts are always 4-byte integers. \n",
    "\n",
    "As a function of N and M, what is the minimum number of bytes of main memory needed to execute the a-priori algorithm on this data? Demonstrate that you have the correct formula by selecting, from the choices below, the triple consisting of values for N, M, and the (approximate, i.e., to within 10%) minumum number of bytes of main memory, S, needed for the a-priori algorithm to execute with this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# N = 100,000; M = 50,000,000; S = 5,000,000,000\n",
    "# N = 40,000; M = 60,000,000; S = 3,200,000,000\n",
    "# N = 50,000; M = 80,000,000; S = 1,500,000,000\n",
    "# N = 100,000; M = 100,000,000; S = 1,200,000,000\n",
    "soln = [[100000, 50000000, 5000000000],\n",
    "        [40000, 60000000, 3200000000],\n",
    "        [50000, 80000000, 1500000000],\n",
    "        [100000, 100000000, 1200000000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def get_min_size(n, m):\n",
    "    return min(2 * n * (n - 1), 12 * (m + 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, m, s in soln:\n",
    "    # YOUR CODE HERE\n",
    "    size = get_min_size(n, m)\n",
    "    if size*1.1 >= s and size*0.9 <= s:\n",
    "        print('N = %f; M = %f; S = %f', n, m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: N = 100,000; M = 100,000,000; S = 1,200,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Imagine there are 100 baskets, numbered 1,2,...,100, and 100 items, similarly numbered. Item i is in basket j if and only if i divides j evenly. For example, basket 24 is the set of items {1,2,3,4,6,8,12,24}. Describe all the association rules that have 100% confidence. Which of the following rules has 100% confidence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets = range(1,101)\n",
    "items = range(1,101)\n",
    "\n",
    "# Create transactions\n",
    "transactions = []\n",
    "\n",
    "for i in baskets:\n",
    "    basket = []\n",
    "    for item in items:\n",
    "        if i % item == 0:\n",
    "            basket.append(item)\n",
    "    transactions.append(basket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def lcm(a, b):\n",
    "    if a > b:\n",
    "        greater = a\n",
    "    else:\n",
    "        greater = b\n",
    "\n",
    "    while True:\n",
    "        if greater % a == 0 and greater % b == 0:\n",
    "            lcm = greater\n",
    "            break\n",
    "        greater += 1\n",
    "\n",
    "    return lcm\n",
    "\n",
    "def get_lcm_for(your_list):\n",
    "    return reduce(lambda x, y: lcm(x, y), your_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence(num,denom):\n",
    "    # YOUR CODE HERE\n",
    "    confidence = (100 // get_lcm_for(num)) / (100 // get_lcm_for(denom))\n",
    "    return 100 * confidence\n",
    "\n",
    "# association rules have 100% confidence if items of num and denom presented in the same baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1,2}-> 4,Condidence = 50\n",
      "{1}-> 2,Condidence = 50\n",
      "{1,4,7}-> 14,Condidence = 100\n",
      "{1,3,6}-> 12,Condidence = 50\n",
      "{4,6}-> 12,Condidence = 100\n",
      "{8,12}-> 96,Condidence = 25\n",
      "{4,6}-> 24,Condidence = 50\n",
      "{1,3,6}-> 12,Condidence = 50\n"
     ]
    }
   ],
   "source": [
    "print(\"{1,2}-> 4,Condidence = %d\"%(confidence([1,2,4],[1,2]))   )\n",
    "print(\"{1}-> 2,Condidence = %d\"%(confidence([1,2],[1]))   )\n",
    "print(\"{1,4,7}-> 14,Condidence = %d\"%(confidence([1,4,7,14],[1,4,7]))   )\n",
    "print(\"{1,3,6}-> 12,Condidence = %d\"%(confidence([1,3,6,12],[1,3,6]))   )\n",
    "print(\"{4,6}-> 12,Condidence = %d\"%(confidence([4,6,12],[4,6]))   )\n",
    "print(\"{8,12}-> 96,Condidence = %d\"%(confidence([8,12,96],[8,12]))   )\n",
    "print(\"{4,6}-> 24,Condidence = %d\"%(confidence([4,6,24],[4,6]))   )\n",
    "print(\"{1,3,6}-> 12,Condidence = %d\"%(confidence([1,3,6,12],[1,3,6])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "Thai Pangsakulyanont",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
