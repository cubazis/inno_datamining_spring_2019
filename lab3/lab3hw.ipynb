{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.layers import Input, Dense, Flatten, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringLayer(Layer):\n",
    "    \n",
    "    \n",
    "    # should have output dim\n",
    "    # weights are centroids\n",
    "    def __init__(self, output_dim, input_dim=None, weights=None, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # kmeans cluster centre locations\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = [InputSpec(ndim=2)]\n",
    "\n",
    "        if self.input_dim:\n",
    "            kwargs['input_shape'] = (self.input_dim,)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = [InputSpec(dtype=K.floatx(),\n",
    "                                     shape=(None, input_dim))]\n",
    "\n",
    "        self.W = K.variable(self.initial_weights)\n",
    "        self.trainable_weights = [self.W]\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        q = 1.0/(1.0 + K.sqrt(K.sum(K.square(K.expand_dims(x, 1) - self.W), axis=2))**2)\n",
    "        q = K.transpose(K.transpose(q)/K.sum(q, axis=1))\n",
    "        return q\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'output_dim': self.output_dim,\n",
    "                  'input_dim': self.input_dim}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepEmbeddingClustering(object):\n",
    "    \n",
    "    # initialize class\n",
    "    def __init__(self, batch_size=256, **kwargs):\n",
    "        super(DeepEmbeddingClustering, self).__init__()\n",
    "        \n",
    "        # MNIST data is 28x28 -> if flatten would be 784\n",
    "        self.input_dim = 784\n",
    "        # number of clusters as stated in the paper\n",
    "        self.n_clusters = 10\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.learning_rate = 0.1\n",
    "        \n",
    "        # how the dimensions will be changed during encoding\n",
    "        self.dims = [self.input_dim, 500, 500, 2000, 10]\n",
    "        \n",
    "        # input layer\n",
    "        self.input_layer = Input(shape=(self.input_dim,))\n",
    "        dropout_fraction = 0.2\n",
    "        std_deviation = 0.01\n",
    "        \n",
    "        self.layer_wise = []\n",
    "        self.encoders = []\n",
    "        self.decoders = []\n",
    "        \n",
    "        # creating layer-wise autoencoder\n",
    "        \n",
    "        for i in range(1, len(self.dims)):\n",
    "            \n",
    "            e_activation = 'linear' if i == (len(self.dims) - 1) else 'relu'\n",
    "            \n",
    "            encoder = Dense(self.dims[i], activation=e_activation,\n",
    "                           input_shape=(self.dims[i-1],),\n",
    "                           kernel_initializer=RandomNormal(mean=0.0, stddev=std_deviation, seed=None),\n",
    "                            bias_initializer='zeros')\n",
    "            self.encoders.append(encoder)\n",
    "            \n",
    "            d_activation = 'linear' if i == 1 else 'relu'\n",
    "            \n",
    "            decoder = Dense(self.dims[i-1], activation=d_activation,\n",
    "                           input_shape=(self.dims[i],),\n",
    "                           kernel_initializer=RandomNormal(mean=0.0, stddev=std_deviation, seed=None),\n",
    "                            bias_initializer='zeros')\n",
    "            \n",
    "            self.decoders.append(decoder)\n",
    "            \n",
    "            autoencoder = Sequential([\n",
    "                Dropout(dropout_fraction),\n",
    "                encoder,\n",
    "                Dropout(dropout_fraction),\n",
    "                decoder\n",
    "            ])\n",
    "            autoencoder.compile(loss='mse',\n",
    "                               optimizer=SGD(lr=self.learning_rate, decay=0, momentum=0.9))\n",
    "            self.layer_wise.append(autoencoder)\n",
    "        \n",
    "        # autoencoder for fine-tuning\n",
    "        self.encoder = Sequential(self.encoders)\n",
    "        self.encoder.compile(loss='mse',\n",
    "                            optimizer=SGD(lr=self.learning_rate, decay=0, momentum=0.9))\n",
    "        # decoders are used in reverse order\n",
    "        self.decoders.reverse()\n",
    "        self.autoencoder = Sequential(self.encoders + self.decoders)\n",
    "        self.autoencoder.compile(loss='mse', optimizer=SGD(lr=self.learning_rate, decay=0, momentum=0.9))\n",
    "        \n",
    "    \n",
    "    def initialize(self, X):\n",
    "        current_input = X\n",
    "        \n",
    "        layerwise_epochs = 50\n",
    "        finetune_epochs = 50\n",
    "        \n",
    "        # layer-wise pretrain\n",
    "        i = 0\n",
    "        for autoencoder in self.layer_wise:\n",
    "            if i > 0:\n",
    "                weights = self.encoders[i-1].get_weights()\n",
    "                dense = Dense(self.dims[i], input_shape=(current_input.shape[1],),\n",
    "                             activation='relu', weights=weights)\n",
    "                \n",
    "                e_model = Sequential([dense])\n",
    "                e_model.compile(loss='mse',\n",
    "                               optimizer=SGD(lr=self.learning_rate, decay=0, momentum=0.9))\n",
    "                current_input = e_model.predict(current_input)\n",
    "                \n",
    "            autoencoder.fit(current_input, current_input, epochs=layerwise_epochs,\n",
    "                            batch_size=self.batch_size)\n",
    "            self.autoencoder.layers[i].set_weights(autoencoder.layers[1].get_weights())\n",
    "            self.autoencoder.layers[len(self.autoencoder.layers) - i - 1].set_weights(autoencoder.layers[-1].get_weights())\n",
    "                \n",
    "            i += 1\n",
    "            \n",
    "            \n",
    "        # fine tuning\n",
    "        self.autoencoder.fit(X, X, epochs=finetune_epochs, batch_size=self.batch_size)\n",
    "        \n",
    "        # finding centroids with k-means\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, n_init=20)\n",
    "        self.y_pred = kmeans.fit_predict(self.encoder.predict(X))\n",
    "        self.centroids = kmeans.cluster_centers_\n",
    "        \n",
    "        self.model = Sequential([self.encoder,\n",
    "                             ClusteringLayer(self.n_clusters,\n",
    "                                                weights=self.centroids,\n",
    "                                                name='clustering')])\n",
    "        self.model.compile(loss='kullback_leibler_divergence', \n",
    "                           optimizer=SGD(lr=self.learning_rate, decay=0, momentum=0.9))\n",
    "        \n",
    "        return self.y_pred\n",
    "        \n",
    "    \n",
    "    def calculate_pi(self, q):\n",
    "        p = q ** 2 / q.sum(0)\n",
    "        return (p.T / p.sum(1)).T\n",
    "    \n",
    "  \n",
    "    def train_cluster(self, X, y, **kwargs):\n",
    "        tol = 0.1\n",
    "        max_iter = 100\n",
    "            \n",
    "        train = True\n",
    "        iteration = 0\n",
    "        \n",
    "        while train:\n",
    "            # stop when reaching maximum iteration\n",
    "            if max_iter < iteration:\n",
    "                train = False\n",
    "            self.q = self.model.predict(X)\n",
    "            self.p = self.calculate_pi(self.q)\n",
    "            \n",
    "            y_pred = self.q.argmax(1)\n",
    "            changed_assignment = 0\n",
    "            for i in range(len(y_pred)):\n",
    "                if y_pred[i] != self.y_pred[i]:\n",
    "                    changed_assignment += 1\n",
    "            \n",
    "            changed_assignment = changed_assignment / len(y_pred)\n",
    "            print('Amount of dots, that changed assignment is ' + str(changed_assignment))\n",
    "            \n",
    "            if changed_assignment < tol:\n",
    "                print('reached tolerance')\n",
    "                train = False\n",
    "            else:\n",
    "                self.y_pred = y_pred\n",
    "                \n",
    "            for i in range(len(self.encoder.layers)):\n",
    "                self.encoder.layers[i].set_weights(self.model.layers[0].layers[i].get_weights())\n",
    "            self.centroids = self.model.layers[-1].get_weights()[0]\n",
    "            \n",
    "            self.model.fit(X, self.p, epochs=50, batch_size=self.batch_size)\n",
    "                \n",
    "            iteration += 1\n",
    "        \n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    # initialize cost matrix for Hungarian algorithm\n",
    "    cost_matrix = np.zeros((10, 10), dtype=np.int64)\n",
    "        \n",
    "    # create cost_matrix\n",
    "    # counts how much each clusterization label\n",
    "    # was equal\n",
    "    for i in range(len(y_pred)):\n",
    "        cost_matrix[y_pred[i], y[i]] += 1\n",
    "            \n",
    "    # algorithm minimizes cost, thus we create \"inverse\" matrix\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix.max() - cost_matrix)\n",
    "        \n",
    "    # row_ind and col_ind corresponds to how we map\n",
    "    # true labels to labels after clusterization\n",
    "    # our cost_matrix contained amount of correct labelling\n",
    "    accuracy = 0\n",
    "    for i, j in zip(row_ind, col_ind):\n",
    "        accuracy += cost_matrix[i, j]\n",
    "            \n",
    "    return accuracy/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234) # set seed for deterministic ordering\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_all = np.concatenate((x_train, x_test), axis = 0)\n",
    "Y = np.concatenate((y_train, y_test), axis = 0)\n",
    "X = x_all.reshape(-1,x_all.shape[1]*x_all.shape[2])\n",
    "    \n",
    "p = np.random.permutation(X.shape[0])\n",
    "X = X[p].astype(np.float32)*0.02\n",
    "Y = Y[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for k_means\n",
      "0.5334\n",
      "Epoch 1/50\n",
      "70000/70000 [==============================] - 9s 124us/step - loss: 0.7270\n",
      "Epoch 2/50\n",
      "70000/70000 [==============================] - 8s 116us/step - loss: 0.4305\n",
      "Epoch 3/50\n",
      "70000/70000 [==============================] - 9s 122us/step - loss: 0.4001\n",
      "Epoch 4/50\n",
      "70000/70000 [==============================] - 8s 120us/step - loss: 0.3856\n",
      "Epoch 5/50\n",
      "70000/70000 [==============================] - 8s 121us/step - loss: 0.3764\n",
      "Epoch 6/50\n",
      "70000/70000 [==============================] - 8s 118us/step - loss: 0.3696\n",
      "Epoch 7/50\n",
      "70000/70000 [==============================] - 8s 119us/step - loss: 0.3643\n",
      "Epoch 8/50\n",
      "70000/70000 [==============================] - 8s 119us/step - loss: 0.3599\n",
      "Epoch 9/50\n",
      "70000/70000 [==============================] - 8s 118us/step - loss: 0.3563\n",
      "Epoch 10/50\n",
      "70000/70000 [==============================] - 9s 125us/step - loss: 0.3532\n",
      "Epoch 11/50\n",
      "70000/70000 [==============================] - 9s 122us/step - loss: 0.3504\n",
      "Epoch 12/50\n",
      "70000/70000 [==============================] - 8s 120us/step - loss: 0.3481\n",
      "Epoch 13/50\n",
      "70000/70000 [==============================] - 8s 120us/step - loss: 0.3457\n",
      "Epoch 14/50\n",
      "70000/70000 [==============================] - 10s 136us/step - loss: 0.3437\n",
      "Epoch 15/50\n",
      "70000/70000 [==============================] - 9s 127us/step - loss: 0.3416\n",
      "Epoch 16/50\n",
      "70000/70000 [==============================] - 9s 125us/step - loss: 0.3396\n",
      "Epoch 17/50\n",
      "70000/70000 [==============================] - 8s 121us/step - loss: 0.3380\n",
      "Epoch 18/50\n",
      "70000/70000 [==============================] - 9s 122us/step - loss: 0.3365\n",
      "Epoch 19/50\n",
      "70000/70000 [==============================] - 9s 126us/step - loss: 0.3343\n",
      "Epoch 20/50\n",
      "70000/70000 [==============================] - 9s 123us/step - loss: 0.3334\n",
      "Epoch 21/50\n",
      "70000/70000 [==============================] - 9s 122us/step - loss: 0.3323\n",
      "Epoch 22/50\n",
      "70000/70000 [==============================] - 9s 126us/step - loss: 0.3303\n",
      "Epoch 23/50\n",
      "70000/70000 [==============================] - 9s 125us/step - loss: 0.3294\n",
      "Epoch 24/50\n",
      "70000/70000 [==============================] - 9s 125us/step - loss: 0.3286\n",
      "Epoch 25/50\n",
      "70000/70000 [==============================] - 9s 124us/step - loss: 0.3273\n",
      "Epoch 26/50\n",
      "70000/70000 [==============================] - 9s 125us/step - loss: 0.3265\n",
      "Epoch 27/50\n",
      "70000/70000 [==============================] - 9s 123us/step - loss: 0.3253\n",
      "Epoch 28/50\n",
      "70000/70000 [==============================] - 9s 123us/step - loss: 0.3247\n",
      "Epoch 29/50\n",
      "70000/70000 [==============================] - 9s 125us/step - loss: 0.3235\n",
      "Epoch 30/50\n",
      "70000/70000 [==============================] - 9s 124us/step - loss: 0.3224\n",
      "Epoch 31/50\n",
      "70000/70000 [==============================] - 9s 124us/step - loss: 0.3223\n",
      "Epoch 32/50\n",
      "70000/70000 [==============================] - 9s 123us/step - loss: 0.3212\n",
      "Epoch 33/50\n",
      "70000/70000 [==============================] - 9s 124us/step - loss: 0.3205\n",
      "Epoch 34/50\n",
      "70000/70000 [==============================] - 9s 123us/step - loss: 0.3196\n",
      "Epoch 35/50\n",
      "70000/70000 [==============================] - 9s 124us/step - loss: 0.3191\n",
      "Epoch 36/50\n",
      "70000/70000 [==============================] - 9s 125us/step - loss: 0.3181\n",
      "Epoch 37/50\n",
      "70000/70000 [==============================] - 9s 125us/step - loss: 0.3175\n",
      "Epoch 38/50\n",
      "70000/70000 [==============================] - 9s 124us/step - loss: 0.3174\n",
      "Epoch 39/50\n",
      "70000/70000 [==============================] - 9s 125us/step - loss: 0.3167\n",
      "Epoch 40/50\n",
      "70000/70000 [==============================] - 10s 140us/step - loss: 0.3161\n",
      "Epoch 41/50\n",
      "70000/70000 [==============================] - 9s 122us/step - loss: 0.3155\n",
      "Epoch 42/50\n",
      "70000/70000 [==============================] - 9s 126us/step - loss: 0.3149\n",
      "Epoch 43/50\n",
      "70000/70000 [==============================] - 9s 129us/step - loss: 0.3148\n",
      "Epoch 44/50\n",
      "70000/70000 [==============================] - 9s 130us/step - loss: 0.3139\n",
      "Epoch 45/50\n",
      "70000/70000 [==============================] - 9s 124us/step - loss: 0.3138\n",
      "Epoch 46/50\n",
      "70000/70000 [==============================] - 9s 130us/step - loss: 0.3131\n",
      "Epoch 47/50\n",
      "70000/70000 [==============================] - 9s 133us/step - loss: 0.3126\n",
      "Epoch 48/50\n",
      "70000/70000 [==============================] - 10s 136us/step - loss: 0.3121\n",
      "Epoch 49/50\n",
      "70000/70000 [==============================] - 9s 128us/step - loss: 0.3118\n",
      "Epoch 50/50\n",
      "70000/70000 [==============================] - 9s 135us/step - loss: 0.3110\n",
      "Epoch 1/50\n",
      "70000/70000 [==============================] - 5s 78us/step - loss: 0.5564\n",
      "Epoch 2/50\n",
      "70000/70000 [==============================] - 6s 83us/step - loss: 0.2609\n",
      "Epoch 3/50\n",
      "70000/70000 [==============================] - 6s 86us/step - loss: 0.2235\n",
      "Epoch 4/50\n",
      "70000/70000 [==============================] - 6s 84us/step - loss: 0.2089\n",
      "Epoch 5/50\n",
      "70000/70000 [==============================] - 6s 80us/step - loss: 0.2013\n",
      "Epoch 6/50\n",
      "70000/70000 [==============================] - 5s 77us/step - loss: 0.1961\n",
      "Epoch 7/50\n",
      "70000/70000 [==============================] - 6s 81us/step - loss: 0.1928\n",
      "Epoch 8/50\n",
      "70000/70000 [==============================] - 6s 87us/step - loss: 0.1900\n",
      "Epoch 9/50\n",
      "70000/70000 [==============================] - 6s 80us/step - loss: 0.1879\n",
      "Epoch 10/50\n",
      "70000/70000 [==============================] - 7s 96us/step - loss: 0.1858\n",
      "Epoch 11/50\n",
      "70000/70000 [==============================] - 7s 100us/step - loss: 0.1822\n",
      "Epoch 12/50\n",
      "70000/70000 [==============================] - 7s 93us/step - loss: 0.1807\n",
      "Epoch 13/50\n",
      "70000/70000 [==============================] - 6s 86us/step - loss: 0.1790\n",
      "Epoch 14/50\n",
      "70000/70000 [==============================] - 6s 87us/step - loss: 0.1778\n",
      "Epoch 15/50\n",
      "70000/70000 [==============================] - 5s 73us/step - loss: 0.1766\n",
      "Epoch 16/50\n",
      "70000/70000 [==============================] - 5s 78us/step - loss: 0.1755\n",
      "Epoch 17/50\n",
      "70000/70000 [==============================] - 6s 80us/step - loss: 0.1741\n",
      "Epoch 18/50\n",
      "70000/70000 [==============================] - 5s 74us/step - loss: 0.1732\n",
      "Epoch 19/50\n",
      "70000/70000 [==============================] - 5s 76us/step - loss: 0.1719\n",
      "Epoch 20/50\n",
      "70000/70000 [==============================] - 5s 75us/step - loss: 0.1712\n",
      "Epoch 21/50\n",
      "70000/70000 [==============================] - 7s 99us/step - loss: 0.1700\n",
      "Epoch 22/50\n",
      "70000/70000 [==============================] - 6s 84us/step - loss: 0.1691\n",
      "Epoch 23/50\n",
      "70000/70000 [==============================] - 6s 82us/step - loss: 0.1683\n",
      "Epoch 24/50\n",
      "70000/70000 [==============================] - 6s 82us/step - loss: 0.1674\n",
      "Epoch 25/50\n",
      "70000/70000 [==============================] - 6s 83us/step - loss: 0.1668\n",
      "Epoch 26/50\n",
      "70000/70000 [==============================] - 6s 92us/step - loss: 0.1659\n",
      "Epoch 27/50\n",
      "70000/70000 [==============================] - 7s 99us/step - loss: 0.1647\n",
      "Epoch 28/50\n",
      "70000/70000 [==============================] - 5s 78us/step - loss: 0.1642\n",
      "Epoch 29/50\n",
      "70000/70000 [==============================] - 7s 96us/step - loss: 0.1632\n",
      "Epoch 30/50\n",
      "70000/70000 [==============================] - 5s 78us/step - loss: 0.1626\n",
      "Epoch 31/50\n",
      "70000/70000 [==============================] - 6s 83us/step - loss: 0.1618\n",
      "Epoch 32/50\n",
      "70000/70000 [==============================] - 6s 80us/step - loss: 0.1612\n",
      "Epoch 33/50\n",
      "70000/70000 [==============================] - 5s 73us/step - loss: 0.1606\n",
      "Epoch 34/50\n",
      "70000/70000 [==============================] - 6s 92us/step - loss: 0.1597\n",
      "Epoch 35/50\n",
      "70000/70000 [==============================] - 7s 102us/step - loss: 0.1591\n",
      "Epoch 36/50\n",
      "70000/70000 [==============================] - 7s 104us/step - loss: 0.1585\n",
      "Epoch 37/50\n",
      "70000/70000 [==============================] - 7s 96us/step - loss: 0.1581\n",
      "Epoch 38/50\n",
      "70000/70000 [==============================] - 6s 91us/step - loss: 0.1571\n",
      "Epoch 39/50\n",
      "70000/70000 [==============================] - 7s 100us/step - loss: 0.1568\n",
      "Epoch 40/50\n",
      "70000/70000 [==============================] - 6s 86us/step - loss: 0.1562\n",
      "Epoch 41/50\n",
      "70000/70000 [==============================] - 6s 90us/step - loss: 0.1556\n",
      "Epoch 42/50\n",
      "70000/70000 [==============================] - 6s 88us/step - loss: 0.1550\n",
      "Epoch 43/50\n",
      "70000/70000 [==============================] - 6s 90us/step - loss: 0.1548\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - 6s 82us/step - loss: 0.1542\n",
      "Epoch 45/50\n",
      "70000/70000 [==============================] - 6s 82us/step - loss: 0.1536\n",
      "Epoch 46/50\n",
      "70000/70000 [==============================] - 6s 81us/step - loss: 0.1532\n",
      "Epoch 47/50\n",
      "70000/70000 [==============================] - 6s 81us/step - loss: 0.1527\n",
      "Epoch 48/50\n",
      "70000/70000 [==============================] - 6s 82us/step - loss: 0.1522\n",
      "Epoch 49/50\n",
      "70000/70000 [==============================] - 6s 91us/step - loss: 0.1520\n",
      "Epoch 50/50\n",
      "70000/70000 [==============================] - 6s 82us/step - loss: 0.1514\n",
      "Epoch 1/50\n",
      "70000/70000 [==============================] - 22s 316us/step - loss: 0.3369\n",
      "Epoch 2/50\n",
      "70000/70000 [==============================] - 23s 321us/step - loss: 0.1332\n",
      "Epoch 3/50\n",
      "70000/70000 [==============================] - 23s 323us/step - loss: 0.1091\n",
      "Epoch 4/50\n",
      "70000/70000 [==============================] - 21s 294us/step - loss: 0.0999\n",
      "Epoch 5/50\n",
      "70000/70000 [==============================] - 21s 304us/step - loss: 0.0949\n",
      "Epoch 6/50\n",
      "70000/70000 [==============================] - 20s 289us/step - loss: 0.0914\n",
      "Epoch 7/50\n",
      "70000/70000 [==============================] - 20s 287us/step - loss: 0.0887\n",
      "Epoch 8/50\n",
      "70000/70000 [==============================] - 20s 291us/step - loss: 0.0869\n",
      "Epoch 9/50\n",
      "70000/70000 [==============================] - 20s 289us/step - loss: 0.0850\n",
      "Epoch 10/50\n",
      "70000/70000 [==============================] - 20s 291us/step - loss: 0.0833\n",
      "Epoch 11/50\n",
      "70000/70000 [==============================] - 20s 288us/step - loss: 0.0820\n",
      "Epoch 12/50\n",
      "70000/70000 [==============================] - 20s 291us/step - loss: 0.0807\n",
      "Epoch 13/50\n",
      "70000/70000 [==============================] - 20s 290us/step - loss: 0.0795\n",
      "Epoch 14/50\n",
      "70000/70000 [==============================] - 21s 305us/step - loss: 0.0785\n",
      "Epoch 15/50\n",
      "70000/70000 [==============================] - 21s 296us/step - loss: 0.0774\n",
      "Epoch 16/50\n",
      "70000/70000 [==============================] - 21s 303us/step - loss: 0.0764\n",
      "Epoch 17/50\n",
      "70000/70000 [==============================] - 22s 313us/step - loss: 0.0755\n",
      "Epoch 18/50\n",
      "70000/70000 [==============================] - 21s 300us/step - loss: 0.0747\n",
      "Epoch 19/50\n",
      "70000/70000 [==============================] - 21s 298us/step - loss: 0.0740\n",
      "Epoch 20/50\n",
      "70000/70000 [==============================] - 21s 299us/step - loss: 0.0732\n",
      "Epoch 21/50\n",
      "70000/70000 [==============================] - 21s 302us/step - loss: 0.0724\n",
      "Epoch 22/50\n",
      "70000/70000 [==============================] - 21s 299us/step - loss: 0.0717\n",
      "Epoch 23/50\n",
      "70000/70000 [==============================] - 22s 307us/step - loss: 0.0710\n",
      "Epoch 24/50\n",
      "70000/70000 [==============================] - 24s 349us/step - loss: 0.0704\n",
      "Epoch 25/50\n",
      "70000/70000 [==============================] - 22s 316us/step - loss: 0.0697\n",
      "Epoch 26/50\n",
      "70000/70000 [==============================] - 22s 310us/step - loss: 0.0691\n",
      "Epoch 27/50\n",
      "70000/70000 [==============================] - 31s 436us/step - loss: 0.0686\n",
      "Epoch 28/50\n",
      "70000/70000 [==============================] - 25s 359us/step - loss: 0.0680\n",
      "Epoch 29/50\n",
      "70000/70000 [==============================] - 21s 300us/step - loss: 0.0675\n",
      "Epoch 30/50\n",
      "70000/70000 [==============================] - 22s 307us/step - loss: 0.0669\n",
      "Epoch 31/50\n",
      "70000/70000 [==============================] - 21s 305us/step - loss: 0.0664\n",
      "Epoch 32/50\n",
      "70000/70000 [==============================] - ETA: 0s - loss: 0.066 - 21s 300us/step - loss: 0.0660\n",
      "Epoch 33/50\n",
      "70000/70000 [==============================] - 21s 304us/step - loss: 0.0655\n",
      "Epoch 34/50\n",
      "70000/70000 [==============================] - 21s 305us/step - loss: 0.0651\n",
      "Epoch 35/50\n",
      "70000/70000 [==============================] - 24s 345us/step - loss: 0.0646\n",
      "Epoch 36/50\n",
      "70000/70000 [==============================] - 23s 324us/step - loss: 0.0641\n",
      "Epoch 37/50\n",
      "70000/70000 [==============================] - 21s 305us/step - loss: 0.0638\n",
      "Epoch 38/50\n",
      "70000/70000 [==============================] - 22s 309us/step - loss: 0.0634\n",
      "Epoch 39/50\n",
      "70000/70000 [==============================] - 22s 308us/step - loss: 0.0630\n",
      "Epoch 40/50\n",
      "70000/70000 [==============================] - 22s 310us/step - loss: 0.0626\n",
      "Epoch 41/50\n",
      "70000/70000 [==============================] - 22s 319us/step - loss: 0.0623\n",
      "Epoch 42/50\n",
      "70000/70000 [==============================] - 22s 316us/step - loss: 0.0620\n",
      "Epoch 43/50\n",
      "70000/70000 [==============================] - 22s 311us/step - loss: 0.0615\n",
      "Epoch 44/50\n",
      "70000/70000 [==============================] - 22s 313us/step - loss: 0.0613\n",
      "Epoch 45/50\n",
      "70000/70000 [==============================] - 22s 314us/step - loss: 0.0610\n",
      "Epoch 46/50\n",
      "70000/70000 [==============================] - 22s 311us/step - loss: 0.0607\n",
      "Epoch 47/50\n",
      "70000/70000 [==============================] - 23s 323us/step - loss: 0.0603\n",
      "Epoch 48/50\n",
      "70000/70000 [==============================] - 21s 305us/step - loss: 0.0600\n",
      "Epoch 49/50\n",
      "70000/70000 [==============================] - 22s 310us/step - loss: 0.0597\n",
      "Epoch 50/50\n",
      "70000/70000 [==============================] - 22s 314us/step - loss: 0.0595\n",
      "Epoch 1/50\n",
      "70000/70000 [==============================] - 5s 69us/step - loss: 0.1211\n",
      "Epoch 2/50\n",
      "70000/70000 [==============================] - 5s 69us/step - loss: 0.1104\n",
      "Epoch 3/50\n",
      "70000/70000 [==============================] - 5s 69us/step - loss: 0.1051\n",
      "Epoch 4/50\n",
      "70000/70000 [==============================] - 5s 71us/step - loss: 0.0987\n",
      "Epoch 5/50\n",
      "70000/70000 [==============================] - 5s 69us/step - loss: 0.0938\n",
      "Epoch 6/50\n",
      "70000/70000 [==============================] - 5s 70us/step - loss: 0.0909\n",
      "Epoch 7/50\n",
      "70000/70000 [==============================] - 5s 68us/step - loss: 0.0895\n",
      "Epoch 8/50\n",
      "70000/70000 [==============================] - 5s 70us/step - loss: 0.0889\n",
      "Epoch 9/50\n",
      "70000/70000 [==============================] - 5s 69us/step - loss: 0.0885\n",
      "Epoch 10/50\n",
      "70000/70000 [==============================] - 5s 70us/step - loss: 0.0884\n",
      "Epoch 11/50\n",
      "70000/70000 [==============================] - 5s 71us/step - loss: 0.0882\n",
      "Epoch 12/50\n",
      "70000/70000 [==============================] - 5s 72us/step - loss: 0.0881\n",
      "Epoch 13/50\n",
      "70000/70000 [==============================] - 5s 70us/step - loss: 0.0880\n",
      "Epoch 14/50\n",
      "70000/70000 [==============================] - 5s 71us/step - loss: 0.0879\n",
      "Epoch 15/50\n",
      "70000/70000 [==============================] - 5s 69us/step - loss: 0.0877\n",
      "Epoch 16/50\n",
      "70000/70000 [==============================] - 5s 70us/step - loss: 0.0876\n",
      "Epoch 17/50\n",
      "70000/70000 [==============================] - 5s 69us/step - loss: 0.0876\n",
      "Epoch 18/50\n",
      "70000/70000 [==============================] - 5s 69us/step - loss: 0.0875\n",
      "Epoch 19/50\n",
      "70000/70000 [==============================] - 5s 69us/step - loss: 0.0874\n",
      "Epoch 20/50\n",
      "70000/70000 [==============================] - 5s 78us/step - loss: 0.0872\n",
      "Epoch 21/50\n",
      "70000/70000 [==============================] - 5s 69us/step - loss: 0.0871\n",
      "Epoch 22/50\n",
      "70000/70000 [==============================] - 5s 74us/step - loss: 0.0870\n",
      "Epoch 23/50\n",
      "70000/70000 [==============================] - 5s 71us/step - loss: 0.0869\n",
      "Epoch 24/50\n",
      "70000/70000 [==============================] - 5s 70us/step - loss: 0.0868\n",
      "Epoch 25/50\n",
      "70000/70000 [==============================] - 5s 71us/step - loss: 0.0867\n",
      "Epoch 26/50\n",
      "70000/70000 [==============================] - 5s 71us/step - loss: 0.0866\n",
      "Epoch 27/50\n",
      "70000/70000 [==============================] - 5s 71us/step - loss: 0.0865\n",
      "Epoch 28/50\n",
      "70000/70000 [==============================] - 5s 71us/step - loss: 0.0864\n",
      "Epoch 29/50\n",
      "70000/70000 [==============================] - 5s 71us/step - loss: 0.0862\n",
      "Epoch 30/50\n",
      "70000/70000 [==============================] - 5s 71us/step - loss: 0.0861\n",
      "Epoch 31/50\n",
      "70000/70000 [==============================] - 5s 71us/step - loss: 0.0860\n",
      "Epoch 32/50\n",
      "70000/70000 [==============================] - 5s 72us/step - loss: 0.0858\n",
      "Epoch 33/50\n",
      "70000/70000 [==============================] - 5s 70us/step - loss: 0.0858\n",
      "Epoch 34/50\n",
      "70000/70000 [==============================] - 5s 74us/step - loss: 0.0856\n",
      "Epoch 35/50\n",
      "70000/70000 [==============================] - 5s 72us/step - loss: 0.0855\n",
      "Epoch 36/50\n",
      "70000/70000 [==============================] - 5s 71us/step - loss: 0.0854\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - 4s 63us/step - loss: 0.0853\n",
      "Epoch 38/50\n",
      "70000/70000 [==============================] - 4s 64us/step - loss: 0.0852\n",
      "Epoch 39/50\n",
      "70000/70000 [==============================] - 4s 62us/step - loss: 0.0851\n",
      "Epoch 40/50\n",
      "70000/70000 [==============================] - 4s 63us/step - loss: 0.0851\n",
      "Epoch 41/50\n",
      "70000/70000 [==============================] - 5s 66us/step - loss: 0.0850\n",
      "Epoch 42/50\n",
      "70000/70000 [==============================] - 5s 66us/step - loss: 0.0849\n",
      "Epoch 43/50\n",
      "70000/70000 [==============================] - 4s 64us/step - loss: 0.0849\n",
      "Epoch 44/50\n",
      "70000/70000 [==============================] - 5s 74us/step - loss: 0.0848\n",
      "Epoch 45/50\n",
      "70000/70000 [==============================] - 4s 62us/step - loss: 0.0848\n",
      "Epoch 46/50\n",
      "70000/70000 [==============================] - 5s 66us/step - loss: 0.0848\n",
      "Epoch 47/50\n",
      "70000/70000 [==============================] - 5s 65us/step - loss: 0.0847\n",
      "Epoch 48/50\n",
      "70000/70000 [==============================] - 5s 67us/step - loss: 0.0847\n",
      "Epoch 49/50\n",
      "70000/70000 [==============================] - 5s 70us/step - loss: 0.0847\n",
      "Epoch 50/50\n",
      "70000/70000 [==============================] - 5s 67us/step - loss: 0.0847\n",
      "Epoch 1/50\n",
      "70000/70000 [==============================] - 40s 573us/step - loss: 0.5556\n",
      "Epoch 2/50\n",
      "70000/70000 [==============================] - 39s 561us/step - loss: 0.4427\n",
      "Epoch 3/50\n",
      "70000/70000 [==============================] - 38s 547us/step - loss: 0.4082\n",
      "Epoch 4/50\n",
      "70000/70000 [==============================] - 38s 546us/step - loss: 0.3873\n",
      "Epoch 5/50\n",
      "70000/70000 [==============================] - 39s 554us/step - loss: 0.3729\n",
      "Epoch 6/50\n",
      "70000/70000 [==============================] - 38s 542us/step - loss: 0.3611\n",
      "Epoch 7/50\n",
      "70000/70000 [==============================] - 40s 569us/step - loss: 0.3525\n",
      "Epoch 8/50\n",
      "70000/70000 [==============================] - 37s 530us/step - loss: 0.3444\n",
      "Epoch 9/50\n",
      "70000/70000 [==============================] - 41s 590us/step - loss: 0.3379\n",
      "Epoch 10/50\n",
      "70000/70000 [==============================] - 40s 576us/step - loss: 0.3321\n",
      "Epoch 11/50\n",
      "70000/70000 [==============================] - 39s 560us/step - loss: 0.3271\n",
      "Epoch 12/50\n",
      "70000/70000 [==============================] - 39s 563us/step - loss: 0.3222\n",
      "Epoch 13/50\n",
      "70000/70000 [==============================] - 39s 560us/step - loss: 0.3185\n",
      "Epoch 14/50\n",
      "70000/70000 [==============================] - 41s 588us/step - loss: 0.3145\n",
      "Epoch 15/50\n",
      "70000/70000 [==============================] - 39s 561us/step - loss: 0.3111\n",
      "Epoch 16/50\n",
      "70000/70000 [==============================] - 40s 567us/step - loss: 0.3077\n",
      "Epoch 17/50\n",
      "70000/70000 [==============================] - 39s 562us/step - loss: 0.3046\n",
      "Epoch 18/50\n",
      "70000/70000 [==============================] - 40s 566us/step - loss: 0.3024\n",
      "Epoch 19/50\n",
      "70000/70000 [==============================] - 40s 569us/step - loss: 0.2995\n",
      "Epoch 20/50\n",
      "70000/70000 [==============================] - 40s 571us/step - loss: 0.2973\n",
      "Epoch 21/50\n",
      "70000/70000 [==============================] - 39s 562us/step - loss: 0.2949\n",
      "Epoch 22/50\n",
      "70000/70000 [==============================] - 40s 571us/step - loss: 0.2928\n",
      "Epoch 23/50\n",
      "70000/70000 [==============================] - 40s 573us/step - loss: 0.2908\n",
      "Epoch 24/50\n",
      "70000/70000 [==============================] - 40s 566us/step - loss: 0.2890\n",
      "Epoch 25/50\n",
      "70000/70000 [==============================] - 40s 572us/step - loss: 0.2870\n",
      "Epoch 26/50\n",
      "70000/70000 [==============================] - 40s 572us/step - loss: 0.2851\n",
      "Epoch 27/50\n",
      "70000/70000 [==============================] - 40s 575us/step - loss: 0.2834\n",
      "Epoch 28/50\n",
      "70000/70000 [==============================] - 40s 568us/step - loss: 0.2817\n",
      "Epoch 29/50\n",
      "70000/70000 [==============================] - 40s 573us/step - loss: 0.2803\n",
      "Epoch 30/50\n",
      "70000/70000 [==============================] - 40s 570us/step - loss: 0.2787\n",
      "Epoch 31/50\n",
      "70000/70000 [==============================] - 40s 569us/step - loss: 0.2775\n",
      "Epoch 32/50\n",
      "70000/70000 [==============================] - 43s 621us/step - loss: 0.2760\n",
      "Epoch 33/50\n",
      "70000/70000 [==============================] - 41s 589us/step - loss: 0.2747\n",
      "Epoch 34/50\n",
      "70000/70000 [==============================] - 44s 622us/step - loss: 0.2734\n",
      "Epoch 35/50\n",
      "70000/70000 [==============================] - 41s 579us/step - loss: 0.2721\n",
      "Epoch 36/50\n",
      "70000/70000 [==============================] - 40s 576us/step - loss: 0.2710\n",
      "Epoch 37/50\n",
      "70000/70000 [==============================] - 43s 607us/step - loss: 0.2696\n",
      "Epoch 38/50\n",
      "70000/70000 [==============================] - 43s 607us/step - loss: 0.2684\n",
      "Epoch 39/50\n",
      "70000/70000 [==============================] - 44s 625us/step - loss: 0.2673\n",
      "Epoch 40/50\n",
      "70000/70000 [==============================] - 40s 578us/step - loss: 0.2662\n",
      "Epoch 41/50\n",
      "70000/70000 [==============================] - 40s 577us/step - loss: 0.2653\n",
      "Epoch 42/50\n",
      "70000/70000 [==============================] - 38s 539us/step - loss: 0.2643\n",
      "Epoch 43/50\n",
      "70000/70000 [==============================] - 44s 627us/step - loss: 0.2633\n",
      "Epoch 44/50\n",
      "70000/70000 [==============================] - 44s 633us/step - loss: 0.2624\n",
      "Epoch 45/50\n",
      "70000/70000 [==============================] - 51s 731us/step - loss: 0.2617\n",
      "Epoch 46/50\n",
      "70000/70000 [==============================] - 44s 633us/step - loss: 0.2603\n",
      "Epoch 47/50\n",
      "70000/70000 [==============================] - 43s 613us/step - loss: 0.2597\n",
      "Epoch 48/50\n",
      "70000/70000 [==============================] - 40s 575us/step - loss: 0.2588\n",
      "Epoch 49/50\n",
      "70000/70000 [==============================] - 40s 574us/step - loss: 0.2578\n",
      "Epoch 50/50\n",
      "70000/70000 [==============================] - 43s 613us/step - loss: 0.2567\n",
      "accuracy for k_means + encoder\n",
      "0.8208\n"
     ]
    }
   ],
   "source": [
    "# kmeans\n",
    "kmeans = KMeans(n_clusters=10, n_init=20)\n",
    "y_pred_kmeans = kmeans.fit_predict(X)\n",
    "print('accuracy for k_means')\n",
    "accuracy = calculate_accuracy(y_pred_kmeans, Y)\n",
    "print(accuracy)\n",
    "\n",
    "mod = DeepEmbeddingClustering(batch_size=256)\n",
    "\n",
    "# returns labels from k-means + trained encoder\n",
    "y_pred_kmeans_encoder = mod.initialize(X)\n",
    "\n",
    "print('accuracy for k_means + encoder')\n",
    "accuracy = calculate_accuracy(y_pred_kmeans_encoder, Y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of dots, that changed assignment is 0.0\n",
      "reached tolerance\n",
      "Epoch 1/50\n",
      "70000/70000 [==============================] - 22s 311us/step - loss: 0.0297\n",
      "Epoch 2/50\n",
      "70000/70000 [==============================] - 20s 292us/step - loss: 0.0193\n",
      "Epoch 3/50\n",
      "70000/70000 [==============================] - 20s 289us/step - loss: 0.0181\n",
      "Epoch 4/50\n",
      "70000/70000 [==============================] - 20s 291us/step - loss: 0.0174\n",
      "Epoch 5/50\n",
      "70000/70000 [==============================] - 20s 289us/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "70000/70000 [==============================] - 20s 292us/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "70000/70000 [==============================] - 21s 299us/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "70000/70000 [==============================] - 20s 291us/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "70000/70000 [==============================] - 21s 294us/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "70000/70000 [==============================] - 21s 300us/step - loss: 0.0156\n",
      "Epoch 11/50\n",
      "70000/70000 [==============================] - 21s 298us/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "70000/70000 [==============================] - 20s 292us/step - loss: 0.0153\n",
      "Epoch 13/50\n",
      "70000/70000 [==============================] - 20s 292us/step - loss: 0.0152\n",
      "Epoch 14/50\n",
      "70000/70000 [==============================] - 21s 293us/step - loss: 0.0151\n",
      "Epoch 15/50\n",
      "70000/70000 [==============================] - 20s 291us/step - loss: 0.0150\n",
      "Epoch 16/50\n",
      "70000/70000 [==============================] - 22s 312us/step - loss: 0.0149\n",
      "Epoch 17/50\n",
      "70000/70000 [==============================] - 20s 288us/step - loss: 0.0148\n",
      "Epoch 18/50\n",
      "70000/70000 [==============================] - 22s 315us/step - loss: 0.0147\n",
      "Epoch 19/50\n",
      "70000/70000 [==============================] - 19s 275us/step - loss: 0.0146\n",
      "Epoch 20/50\n",
      "70000/70000 [==============================] - 17s 250us/step - loss: 0.0145\n",
      "Epoch 21/50\n",
      "70000/70000 [==============================] - 17s 250us/step - loss: 0.0145\n",
      "Epoch 22/50\n",
      "70000/70000 [==============================] - 17s 248us/step - loss: 0.0144\n",
      "Epoch 23/50\n",
      "70000/70000 [==============================] - 19s 269us/step - loss: 0.0143\n",
      "Epoch 24/50\n",
      "70000/70000 [==============================] - 18s 251us/step - loss: 0.0143\n",
      "Epoch 25/50\n",
      "70000/70000 [==============================] - 18s 251us/step - loss: 0.0142\n",
      "Epoch 26/50\n",
      "70000/70000 [==============================] - 19s 265us/step - loss: 0.0141\n",
      "Epoch 27/50\n",
      "70000/70000 [==============================] - 20s 287us/step - loss: 0.0141\n",
      "Epoch 28/50\n",
      "70000/70000 [==============================] - 20s 289us/step - loss: 0.0140\n",
      "Epoch 29/50\n",
      "70000/70000 [==============================] - 22s 317us/step - loss: 0.0140\n",
      "Epoch 30/50\n",
      "70000/70000 [==============================] - 25s 354us/step - loss: 0.0139\n",
      "Epoch 31/50\n",
      "70000/70000 [==============================] - 27s 390us/step - loss: 0.0139\n",
      "Epoch 32/50\n",
      "70000/70000 [==============================] - 22s 320us/step - loss: 0.0138\n",
      "Epoch 33/50\n",
      "70000/70000 [==============================] - 19s 268us/step - loss: 0.0138\n",
      "Epoch 34/50\n",
      "70000/70000 [==============================] - 21s 297us/step - loss: 0.0138\n",
      "Epoch 35/50\n",
      "70000/70000 [==============================] - 19s 277us/step - loss: 0.0137\n",
      "Epoch 36/50\n",
      "70000/70000 [==============================] - 19s 271us/step - loss: 0.0137\n",
      "Epoch 37/50\n",
      "70000/70000 [==============================] - 22s 309us/step - loss: 0.0136\n",
      "Epoch 38/50\n",
      "70000/70000 [==============================] - 23s 326us/step - loss: 0.0136\n",
      "Epoch 39/50\n",
      "70000/70000 [==============================] - 30s 432us/step - loss: 0.0136\n",
      "Epoch 40/50\n",
      "70000/70000 [==============================] - 21s 302us/step - loss: 0.0135\n",
      "Epoch 41/50\n",
      "70000/70000 [==============================] - 19s 275us/step - loss: 0.0135\n",
      "Epoch 42/50\n",
      "70000/70000 [==============================] - 22s 307us/step - loss: 0.0135\n",
      "Epoch 43/50\n",
      "70000/70000 [==============================] - 21s 303us/step - loss: 0.0134\n",
      "Epoch 44/50\n",
      "70000/70000 [==============================] - 22s 310us/step - loss: 0.0134\n",
      "Epoch 45/50\n",
      "70000/70000 [==============================] - 19s 269us/step - loss: 0.0134\n",
      "Epoch 46/50\n",
      "70000/70000 [==============================] - 20s 286us/step - loss: 0.0133\n",
      "Epoch 47/50\n",
      "70000/70000 [==============================] - 20s 293us/step - loss: 0.0133\n",
      "Epoch 48/50\n",
      "70000/70000 [==============================] - 22s 315us/step - loss: 0.0133\n",
      "Epoch 49/50\n",
      "70000/70000 [==============================] - 20s 283us/step - loss: 0.0133\n",
      "Epoch 50/50\n",
      "70000/70000 [==============================] - 22s 313us/step - loss: 0.0132\n",
      "accuracy for DEC\n",
      "0.8277857142857142\n"
     ]
    }
   ],
   "source": [
    "# dec model\n",
    "dec_model = mod.train_cluster(X, Y)\n",
    "y_pred_dec = dec_model.predict(X).argmax(1)\n",
    "print('accuracy for DEC')\n",
    "accuracy = calculate_accuracy(y_pred_dec, Y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
