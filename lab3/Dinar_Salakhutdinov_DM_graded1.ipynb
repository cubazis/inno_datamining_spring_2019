{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dinar_Salakhutdinov_DM_graded1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "HnxP1ZjxN62J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Accuracy calculation function:"
      ]
    },
    {
      "metadata": {
        "id": "TDSeWcJnMfpn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Function to calculate accuracy (TAKEN FROM ORIGINAL CODE):\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "    y_true = y_true.astype(np.int64)\n",
        "    assert y_pred.size == y_true.size\n",
        "    D = max(y_pred.max(), y_true.max()) + 1\n",
        "    w = np.zeros((D, D), dtype=np.int64)\n",
        "    for i in range(y_pred.size):\n",
        "        w[y_pred[i], y_true[i]] += 1\n",
        "    from sklearn.utils.linear_assignment_ import linear_assignment\n",
        "    ind = linear_assignment(w.max() - w)\n",
        "    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZEL7QJbhH08_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Estimate accuracy score for K_Means:"
      ]
    },
    {
      "metadata": {
        "id": "uGL9NXMEIBKQ",
        "colab_type": "code",
        "outputId": "85d4812c-f390-4dfb-891e-f9f48ef8b442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets.mnist import load_data\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "x = np.concatenate((x_train, x_test))\n",
        "y = np.concatenate((y_train, y_test))\n",
        "x = x.reshape((x.shape[0], -1))\n",
        "\n",
        "k_means = KMeans(n_clusters=len(np.unique(y)))\n",
        "y_est_k_means = k_means.fit_predict(x)\n",
        "\n",
        "print(calculate_accuracy(y, y_est_k_means))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "0.5323571428571429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wlTYeWKkeVix",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Implement autoencoder, train it and estimate score for encoder + K_Means:"
      ]
    },
    {
      "metadata": {
        "id": "rM5W8rVUSirq",
        "colab_type": "code",
        "outputId": "29d2da87-05d3-4021-a7ac-fae88a7a0ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Input\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(784,), name='input') \n",
        "\n",
        "current = Dense(500, activation='relu')(input_layer)\n",
        "current = Dense(500, activation='relu')(current)\n",
        "current = Dense(2000, activation='relu')(current)\n",
        "\n",
        "encoding_result = Dense(10)(current)\n",
        "\n",
        "current = Dense(2000, activation='relu')(encoding_result)\n",
        "current = Dense(500, activation='relu')(current)\n",
        "current = Dense(500, activation='relu')(current)\n",
        "\n",
        "current = Dense(784)(current)\n",
        "\n",
        "decoding_result = current\n",
        "\n",
        "autoencoder_full = Model(inputs=input_layer, outputs=decoding_result, name='autoencoder')\n",
        "autoencoder_without_decoder = Model(inputs=input_layer, outputs=encoding_result, name='encoder')\n",
        "\n",
        "autoencoder_full.compile(loss = 'mse', optimizer='adam')\n",
        "autoencoder_full.fit(x, x, batch_size=256, epochs=20)\n",
        "\n",
        "k_means_after_encoding = KMeans(n_clusters=10)\n",
        "y_predicted = k_means_after_encoding.fit_predict(autoencoder_without_decoder.predict(x))\n",
        "\n",
        "print()\n",
        "print(calculate_accuracy(y, y_predicted))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "70000/70000 [==============================] - 44s 628us/step - loss: 2487.8858\n",
            "Epoch 2/20\n",
            "70000/70000 [==============================] - 43s 616us/step - loss: 1421.7480\n",
            "Epoch 3/20\n",
            "70000/70000 [==============================] - 43s 614us/step - loss: 1247.7960\n",
            "Epoch 4/20\n",
            "70000/70000 [==============================] - 43s 612us/step - loss: 1156.8260\n",
            "Epoch 5/20\n",
            "70000/70000 [==============================] - 42s 605us/step - loss: 1095.3879\n",
            "Epoch 6/20\n",
            "70000/70000 [==============================] - 42s 604us/step - loss: 1046.1051\n",
            "Epoch 7/20\n",
            "70000/70000 [==============================] - 44s 622us/step - loss: 1008.7352\n",
            "Epoch 8/20\n",
            "70000/70000 [==============================] - 44s 625us/step - loss: 979.4484\n",
            "Epoch 9/20\n",
            "70000/70000 [==============================] - 45s 636us/step - loss: 954.1710\n",
            "Epoch 10/20\n",
            "70000/70000 [==============================] - 45s 641us/step - loss: 932.1156\n",
            "Epoch 11/20\n",
            "70000/70000 [==============================] - 45s 636us/step - loss: 910.7614\n",
            "Epoch 12/20\n",
            "70000/70000 [==============================] - 44s 630us/step - loss: 894.4627\n",
            "Epoch 13/20\n",
            "70000/70000 [==============================] - 44s 632us/step - loss: 883.2274\n",
            "Epoch 14/20\n",
            "70000/70000 [==============================] - 44s 622us/step - loss: 864.2813\n",
            "Epoch 15/20\n",
            "70000/70000 [==============================] - 44s 624us/step - loss: 853.3680\n",
            "Epoch 16/20\n",
            "70000/70000 [==============================] - 43s 615us/step - loss: 841.7143\n",
            "Epoch 17/20\n",
            "70000/70000 [==============================] - 43s 613us/step - loss: 831.6199\n",
            "Epoch 18/20\n",
            "70000/70000 [==============================] - 44s 623us/step - loss: 822.6896\n",
            "Epoch 19/20\n",
            "70000/70000 [==============================] - 44s 627us/step - loss: 811.9570\n",
            "Epoch 20/20\n",
            "70000/70000 [==============================] - 44s 628us/step - loss: 806.0859\n",
            "\n",
            "0.7969714285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c2NCgIqcgAg9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "DEC:"
      ]
    },
    {
      "metadata": {
        "id": "ZcfybCtFgda4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Taken from https://github.com/XifengGuo/DEC-keras/blob/master/DEC.py:\n",
        "\n",
        "from keras import backend\n",
        "from keras.layers import Layer, InputSpec\n",
        "\n",
        "\n",
        "class Clustering(Layer):\n",
        "\n",
        "    def __init__(self, n_clusters, **kwargs):\n",
        "        input_shape = (10,10)\n",
        "        super(Clustering, self).__init__(**kwargs)\n",
        "        self.n_clusters=10\n",
        "        self.alpha = 1.0\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        input_dimension = input_shape[1]\n",
        "        self.input_spec = InputSpec(dtype=backend.floatx(), shape=(None, input_dimension))\n",
        "        self.clusters = self.add_weight((self.n_clusters, input_dimension), initializer='glorot_uniform', name='clusters')\n",
        "        super(Clustering, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        q = 1.0 / (1.0 + (backend.sum(backend.square(backend.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
        "        q **= (self.alpha + 1.0) / 2.0\n",
        "        return backend.transpose(backend.transpose(q) / backend.sum(q, axis=1)) \n",
        "        \n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.n_clusters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SR0vDo_VL7Uw",
        "colab_type": "code",
        "outputId": "d47632f0-76f0-4f6a-fcd9-0a64cffb1a9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "n_clusters = 10\n",
        "\n",
        "clustering_layer = Clustering(n_clusters, name='clustering')(autoencoder_without_decoder.output)\n",
        "\n",
        "model = Model(inputs=autoencoder_without_decoder.input, outputs=clustering_layer)\n",
        "\n",
        "kmeans = KMeans(n_clusters=n_clusters, n_init=20)\n",
        "kmeans.fit(autoencoder_without_decoder.predict(x))\n",
        "\n",
        "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
        "\n",
        "\n",
        "model.compile(optimizer=SGD(0.01, 0.9), loss='kld')\n",
        "\n",
        "index_array = np.arange(x.shape[0])\n",
        "index = 0\n",
        "maxiter = 5000\n",
        "update_interval = 150\n",
        "batch_size = 256\n",
        "\n",
        "for iteration in range(maxiter):\n",
        "  \n",
        "    if iteration % update_interval == 0:\n",
        "        q = model.predict(x, verbose=0)\n",
        "        p = ((q ** 2 / q.sum(0)).T / (q ** 2 / q.sum(0)).sum(1)).T\n",
        "        y_pred = q.argmax(1)\n",
        "        \n",
        "    idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]\n",
        "    index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0\n",
        "    \n",
        "print(calculate_accuracy(y, y_pred))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8376857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}